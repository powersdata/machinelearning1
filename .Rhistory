for (i in 1:ncol(training)) {
if (names(training[i]) == "magnet_dumbbell_y") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
# qqnorm(training[[i]], main=names(training[i]))
}
}
par(mfrow = c(1, 2))
for (i in 1:ncol(training)) {
if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
# qqnorm(training[[i]], main=names(training[i]))
}
}
for (i in 1:ncol(training)) {
#    if (names(training[i]) == "roll_belt") {
#        hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
#        plot(training[[i]], main = names(training[i]))
qqnorm(training[[i]], main=names(training[i]))
}
}
par(mfrow = c(11, 5))
for (i in 1:ncol(training)) {
#    if (names(training[i]) == "roll_belt") {
#        hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
#        plot(training[[i]], main = names(training[i]))
qqnorm(training[[i]], main=names(training[i]))
}
}
dev.off()
par(mfrow = c(11, 5))
for (i in 1:ncol(training)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
par(mfrow = c(53, 2))
for (i in 1:ncol(training)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
}
par(mfrow = c(52, 2))
for (i in 1:ncol(training)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
?mfrow
par(mfrow = c(5, 2))
for (i in 1:ncol(training)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
par(mfrow = c(2, 2))
for (i in 1:ncol(training)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
}
par(mfrow = c(3, 4))
for (i in 1:ncol(training)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
3
par(mfrow = c(3, 5))
for (i in 1:ncol(training)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
#plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
for (i in 1:(ncol(training)-1)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
#plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
par(mfrow = c(11, 5))
for (i in 1:(ncol(training)-1)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
#plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
par(mfrow = c(9, 6))
for (i in 1:(ncol(training)-1)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
#plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
par(mfrow = c(4, 6))
for (i in 1:(ncol(training)-1)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
#plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
par(mfrow = c(3, 6))
for (i in 1:(ncol(training)-1)) {
#    if (names(training[i]) == "roll_belt") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
#plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
par(mfrow = c(4, 6))
for (i in 1:(ncol(training)-1)) {
#    if (names(training[i]) == "roll_belt") {
#hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
par(mfrow = c(3, 6))
for (i in 1:(ncol(training)-1)) {
#    if (names(training[i]) == "roll_belt") {
#hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
for (i in 1:18 {
for (i in 1:18) {
#    if (names(training[i]) == "roll_belt") {
#hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
dev.off()
par(mfrow = c(1, 1))
#for (i in 1:(ncol(training)-1)) {
for (i in 1:18) {
if (names(training[i]) == "roll_belt") {
#hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
}
par(mfrow = c(3, 5))
#for (i in 1:(ncol(training)-1)) {
for (i in 1:15) {
if (names(training[i]) == "roll_belt") {
#hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
}
par(mfrow = c(3, 5))
#for (i in 1:(ncol(training)-1)) {
for (i in 1:15) {
#    if (names(training[i]) == "roll_belt") {
#hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
training$accel_belt_y > 100
sum(training$accel_belt_y > 100)
sum(training$accel_belt_y < 50)
sum(training$accel_belt_y < -50)
for (i in 16:30) {
#    if (names(training[i]) == "roll_belt") {
#hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
sum(training$total_accel_dumbbell > 50)
for (i in 31:45) {
#    if (names(training[i]) == "roll_belt") {
#hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
sum(training$gyros_dumbbell_x < -50)
sum(training$gyros_dumbbell_y > 10)
sum(training$gyros_dumbbell_z > 10)
for (i in 46:52) {
#    if (names(training[i]) == "roll_belt") {
#hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
sum(training$accel_forearm_y > 800)
for (i in 1:15) {
#    if (names(training[i]) == "roll_belt") {
#hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
par(mfrow = c(1, 2))
for (i in 1:(ncol(training)-1)) {
#for (i in 1:15) {
if (names(training[i]) == "training$accel_belt_y") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
}
dev.off()
par(mfrow = c(1, 2))
for (i in 1:(ncol(training)-1)) {
#for (i in 1:15) {
if (names(training[i]) == "training$accel_belt_y") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
}
par(mfrow = c(1, 2))
for (i in 1:(ncol(training)-1)) {
#for (i in 1:15) {
if (names(training[i]) == "accel_belt_y") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
}
dim(training)
abn.rows <- training$accel_belt_y > 100 | training$accel_belt_y < -50 | training$total_accel_dumbbell > 50 |
training$gyros_dumbbell_x < -50 | training$gyros_dumbbell_y > 10 | training$gyros_dumbbell_z  > 10 |
training$magnet_dumbbell_y < -2000 | training$total_accel_forearm > 90 | training$gyros_forearm_x < -10 |
training$gyros_forearm_y > 50 | training$gyros_forearm_z > 50 | training$accel_forearm_y > 800
training <- training[!abn.rows, ]
testing <- testing[!abn.rows]
dim(training)
rm(training)
setwd("~/GitHub/machinelearning1")
if (!dir.exists("data")) { dir.create("data")}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- "train.csv"
trainFilePath <- paste(getwd(),"data", trainFile, sep = "/")
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- "test.csv"
testFilePath <- paste(getwd(),"data", testFile, sep = "/")
## Download Files from internet only if not in data directory
if (!file.exists(paste(getwd(), "data", "train.csv", sep ="/"))) {
setInternet2(use = TRUE)
download.file(trainUrl, destfile = trainFilePath)
}
if (!file.exists(paste(getwd(), "data", "test.csv", sep ="/"))) {
setInternet2(use = TRUE)
download.file(testUrl, destfile = testFilePath)
}
## load the file from disk only if it
## hasn't already been read into a variable
if(!(exists("training"))) {
training <- read.csv(trainFilePath, na.strings = c("NA","#DIV/0!",""))
}
if(!(exists("test"))) {
test <- read.csv(testFilePath, na.strings = c("NA","#DIV/0!",""))
}
raw.training <- training
rm(testFile, testFilePath, testUrl, trainFile, trainFilePath, trainUrl)
featured.cols <- grep("^max|^min|^ampl|^var|^avg|^stdd|^ske|^kurt", names(raw.training))
training <- rawdata.train[-featured.cols]
training <- training[-featured.cols]
nearzero <- nearZeroVar(training, saveMetrics = TRUE)
library(caret)
library(rattle)
library(gbm)
nearzero <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[, !nearzero$nzv]
raw.training <- training
rm(training)
setwd("~/GitHub/machinelearning1")
if (!dir.exists("data")) { dir.create("data")}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- "train.csv"
trainFilePath <- paste(getwd(),"data", trainFile, sep = "/")
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- "test.csv"
testFilePath <- paste(getwd(),"data", testFile, sep = "/")
## Download Files from internet only if not in data directory
if (!file.exists(paste(getwd(), "data", "train.csv", sep ="/"))) {
setInternet2(use = TRUE)
download.file(trainUrl, destfile = trainFilePath)
}
if (!file.exists(paste(getwd(), "data", "test.csv", sep ="/"))) {
setInternet2(use = TRUE)
download.file(testUrl, destfile = testFilePath)
}
## load the file from disk only if it
## hasn't already been read into a variable
if(!(exists("raw.training"))) {
raw.training <- read.csv(trainFilePath, na.strings = c("NA","#DIV/0!",""))
}
if(!(exists("test"))) {
test <- read.csv(testFilePath, na.strings = c("NA","#DIV/0!",""))
}
training <- raw.training
rm(testFile, testFilePath, testUrl, trainFile, trainFilePath, trainUrl)
rm(raw.training)
setwd("~/GitHub/machinelearning1")
if (!dir.exists("data")) { dir.create("data")}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- "train.csv"
trainFilePath <- paste(getwd(),"data", trainFile, sep = "/")
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- "test.csv"
testFilePath <- paste(getwd(),"data", testFile, sep = "/")
## Download Files from internet only if not in data directory
if (!file.exists(paste(getwd(), "data", "train.csv", sep ="/"))) {
setInternet2(use = TRUE)
download.file(trainUrl, destfile = trainFilePath)
}
if (!file.exists(paste(getwd(), "data", "test.csv", sep ="/"))) {
setInternet2(use = TRUE)
download.file(testUrl, destfile = testFilePath)
}
## load the file from disk only if it
## hasn't already been read into a variable
if(!(exists("raw.training"))) {
raw.training <- read.csv(trainFilePath, na.strings = c("NA","#DIV/0!",""))
}
if(!(exists("test"))) {
test <- read.csv(testFilePath, na.strings = c("NA","#DIV/0!",""))
}
training <- raw.training
rm(testFile, testFilePath, testUrl, trainFile, trainFilePath, trainUrl)
featured.cols <- grep("^max|^min|^ampl|^var|^avg|^stdd|^ske|^kurt", names(raw.training))
training <- training[-featured.cols]
#Removed variables related with data acquisition (like: id, timestamps, individuals’ names, etc.)
training <- training[, -(1:6)]
nearzero <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[, !nearzero$nzv]
View(nearzero)
toberem <-sapply(colnames(training), function(x)
if (sum(is.na(training[, x])) > 0.30 * nrow(training))
{return(TRUE)}
else{return(FALSE)})
training <- training[,!toberem]
training <- training[,!toberem]
rm(nearzero, toberem)
training <- raw.training
featured.cols <- grep("^max|^min|^ampl|^var|^avg|^stdd|^ske|^kurt", names(raw.training))
training <- training[-featured.cols]
#Removed variables related with data acquisition (like: id, timestamps, individuals’ names, etc.)
training <- training[, -(1:7)]
```
```{r, echo=T, message=FALSE, warning=FALSE, cache = FALSE, results="markup"}
#Removed all variables that had little variance
nearzero <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[, !nearzero$nzv]
#Removed all variables that had more than 30% of the data missing
toberem <-sapply(colnames(training), function(x)
if (sum(is.na(training[, x])) > 0.30 * nrow(training))
{return(TRUE)}
else{return(FALSE)})
training <- training[,!toberem]
dev.off()
###Summary
Accelerometers were used to capture 6 participants doing Unilateral Dumbbell Biceps Curls.  Participants were ask to perform the curls in 5 different ways or classes.  Our model was created using the data from the accelerometers on the belt, forearm, arm, and dumbell.  We are trying to predict the manner in which the curl was performed.
The following packages were used to obtain the predicted results along with the random seed set to 42.
```{r, echo=T, message=FALSE, warning=FALSE, cache = FALSE, results='markup'}
#detach(package:igraph, unload=TRUE)#library(klaR)
#library(abind)
#library(arm)
#library(MASS)
library(caret)
#library(ggplot2)
#library(randomForest)
library(rattle)
library(gbm)
#detach("package:ggplot2", unload=TRUE)
#library(kernlab)
#library()
set.seed(42)
```
###Data
The training data for this project are available here:
<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>
The test data are available here:
<https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>
More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).
```{r, echo=F, message=FALSE, warning=FALSE, cache = FALSE, results="hide"}
setwd("~/GitHub/machinelearning1")
if (!dir.exists("data")) { dir.create("data")}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
trainFile <- "train.csv"
trainFilePath <- paste(getwd(),"data", trainFile, sep = "/")
testUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
testFile <- "test.csv"
testFilePath <- paste(getwd(),"data", testFile, sep = "/")
## Download Files from internet only if not in data directory
if (!file.exists(paste(getwd(), "data", "train.csv", sep ="/"))) {
setInternet2(use = TRUE)
download.file(trainUrl, destfile = trainFilePath)
}
if (!file.exists(paste(getwd(), "data", "test.csv", sep ="/"))) {
setInternet2(use = TRUE)
download.file(testUrl, destfile = testFilePath)
}
## load the file from disk only if it
## hasn't already been read into a variable
if(!(exists("raw.training"))) {
raw.training <- read.csv(trainFilePath, na.strings = c("NA","#DIV/0!",""))
}
if(!(exists("test"))) {
test <- read.csv(testFilePath, na.strings = c("NA","#DIV/0!",""))
}
training <- raw.training
rm(testFile, testFilePath, testUrl, trainFile, trainFilePath, trainUrl)
```
###Cleaning the Training-Set
Included in the dataset are featured columns that the authors used to characterize the performance classes.  These columns of data features the max/min value, average, skewness, etc. of the performance class and are not relevant to include as a predictor.  In addition to removing these featured columns, I looked but did not find columns that had near zero variance or lots of missing data.  As a result, the number of predictors for 'classe' was reduced to 52.
While this reduction may reduce our accuracy for our testing set by allowing more in-sample errors, it has several added benefits.
- The processing speed and computational requirements are reduced.
- Reduces likelihood of overfitting the model to the training data and thus insuring that the out-of-sample errors are more accurate.
```{r, echo=T, message=FALSE, warning=FALSE, cache = FALSE, results="markup"}
# Remove all feature columns
featured.cols <- grep("^max|^min|^ampl|^var|^avg|^stdd|^ske|^kurt", names(raw.training))
training <- training[-featured.cols]
#Removed variables related with data acquisition (like: id, timestamps, individuals’ names, etc.)
training <- training[, -(1:7)]
#Removed all variables that had little variance
nearzero <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[, !nearzero$nzv]
#Removed all variables that had more than 30% of the data missing
toberem <-sapply(colnames(training), function(x)
if (sum(is.na(training[, x])) > 0.30 * nrow(training))
{return(TRUE)}
else{return(FALSE)})
training <- training[,!toberem]
rm(nearzero, toberem)
rm(nearzero, toberem, featured.cols)
###Partioning the training set into two
The training data is partitioned into two data sets, 75% for training, 25% for testing:
```{r, echo=T, message=FALSE, warning=FALSE, cache = FALSE, results="markup"}
inTrain <- createDataPartition(y=training$classe, p=.75, list=FALSE)
testing <- training[-inTrain, ]
training <- training[inTrain, ]
rm(inTrain)
# Explore plots to determine outliers
par(mfrow = c(1, 2))
for (i in 1:(ncol(training)-1)) {
#for (i in 1:15) {
if (names(training[i]) == "accel_belt_y") {
hist(training[[i]], xlab = names(training[i]), main = names(training[i]))
plot(training[[i]], main = names(training[i]))
#qqnorm(training[[i]], main=names(training[i]))
}
}
dim(training)
out.rows <- training$accel_belt_y > 100 | training$accel_belt_y < -50 | training$total_accel_dumbbell > 50 |
training$gyros_dumbbell_x < -50 | training$gyros_dumbbell_y > 10 | training$gyros_dumbbell_z  > 10 |
training$magnet_dumbbell_y < -2000 | training$total_accel_forearm > 90 | training$gyros_forearm_x < -10 |
training$gyros_forearm_y > 50 | training$gyros_forearm_z > 50 | training$accel_forearm_y > 800
training <- training[!out.rows, ]
testing <- testing[!out.rows]
dim(training)
tc <- trainControl(method = "cv", number = 7, verboseIter=FALSE , preProcOptions="pca", allowParallel=TRUE)
rm(i, out.rows)
preObj <- preProcess(x = training, method = c("center", "scale", "pca"), thresh = 0.9)
training.pre <- predict(preObj, training)
print(preObj)
gbm.cv.model <- train(training.pre, training, method = "gbm", trControl = tc, verbose = FALSE)
tc <- trainControl(method = "cv", number = 7, verboseIter=FALSE, allowParallel=TRUE)
gbm.cv.model <- train(training.pre, training, method = "gbm", trControl = tc)
preObj <- preProcess(x = training, method = c("center", "scale", "pca"), thresh = 0.95)
training.pre <- predict(preObj, training)
print(preObj)
tc <- trainControl(method = "cv", number = 5, verboseIter=FALSE, allowParallel=TRUE)
gbm.cv.model <- train(training.pre, training, method = "gbm", trControl = tc)
tc <- trainControl(method = "cv", number = 7, verboseIter=FALSE , preProcOptions="pca", allowParallel=TRUE)
gbm.cv.model <- train(training.pre, training, method = "gbm", trControl = tc)
tc <- trainControl(method = "cv", number = 7, verboseIter=FALSE , preProcOptions="pca", allowParallel=TRUE)
preObj <- preProcess(x = training, method = "pca", thresh = 0.95)
training.pre <- predict(preObj, training)
print(preObj)
preObj <- preProcess(x = training, method = "pca")
training.pre <- predict(preObj, training)
print(preObj)
tc <- trainControl(method = "cv", number = 7, verboseIter=FALSE , preProcOptions="pca", allowParallel=TRUE)
gbm.cv.model <- suppressMessages(train(classe ~., data = training, method="gbm", trControl = tc))
gbm.cv.model$results$Accuracy
rf.cv.model <- suppressMessages(train(classe ~ ., data = training, method = "rf", trControl= tc))
lda.cv.model <- suppressMessages(train(classe ~ ., data = training, method = "lda", trControl= tc))
```
Accuracy comparision
```{r, echo=F, message=FALSE, warning=FALSE, cache = FALSE, results="asis"}
model <- c("Random Forest", "Gradient Boosting", "Linear Discriminate Analysis" )
Accuracy <- c(
max(rf.cv.model$results$Accuracy),
max(gbm.cv.model$results$Accuracy),
max(lda.cv.model$results$Accuracy)
)
performance <- cbind(model,Accuracy)
knitr::kable(performance)
```
Random forest provides the best results and will provide the predictions for the submission. Even if the Out of sample error cannot be estimated exactly, the in-sample error obtained through cross-validation is calculated over different test sets and should provide a better estimate of out-of sample error with respect to the case of no cross-validation.
##Prediction of “classe” variable for the test set
```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results="hide"}
#rf.Pred <- predict(rf.model, testing)
rf.cv.Pred <- predict(rf.cv.model, testing)
gbm.cv.Pred <- predict(gbm.cv.model, testing)
```
Checking if the models give same predictions
```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results="hide"}
#confusionMatrix(rf.Pred, testing$classe)
confusionMatrix(rf.cv.Pred, testing$classe)
confusionMatrix(gbm.cv.Pred, testing$classe)
dev.off()
