{
    "contents" : "---\ntitle: \"Predictive Barbell Lifts\"\nauthor: \"Ted Powers\"\ndate: \"December 12, 2015\"\noutput: html_document\n---\n\n###Summary\nIn this project, data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants will be used.  From this data, the goal is to predict which of the 5 classes of dumbell lifts was performed and whether the exercise was performed correctly.  \n\nInstalled package dependencies:\n```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results=\"hide\"}\nlibrary(caret)\n```\n\n###Data\nThe training data for this project are available here: \n\nhttps://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\n\nThe test data are available here: \n\nhttps://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\n\nMore information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset). \n\n\n```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results=\"hide\"}\nsetwd(\"~/GitHub/machinelearning1\")\nif (!dir.exists(\"data\")) { dir.create(\"data\")}\n\nif (!file.exists(paste(getwd(), \"data\", \"train.csv\", sep =\"/\"))) {\n        trainUrl <- \"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\n        trainFile <- \"train.csv\"\n        trainFilePath <- paste(getwd(),\"data\", trainFile, sep = \"/\")\n         setInternet2(use = TRUE)\n        download.file(trainUrl, destfile = trainFilePath)\n        training <- read.csv(trainFilePath, na.strings = c(\"NA\",\"#DIV/0!\",\"\"))\n}\nif (!file.exists(paste(getwd(), \"data\", \"test.csv\", sep =\"/\"))) {\n        testUrl <- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\n        testFile <- \"test.csv\"\n        testFilePath <- paste(getwd(),\"data\", testFile, sep = \"/\")\n        setInternet2(use = TRUE)\n        download.file(testUrl, destfile = testFilePath)\n        testing <- read.csv(testFilePath, na.strings = c(\"NA\",\"#DIV/0!\",\"\"))\n}\n\n## load the file from disk only if it \n## hasn't already been read into a variable\nif(!(exists(\"training\"))) {\n        trainFile <- \"train.csv\"\n        trainFilePath <- paste(getwd(),\"data\", trainFile, sep = \"/\")\n        training <- read.csv(trainFilePath, na.strings = c(\"NA\",\"#DIV/0!\",\"\"))\n}\nif(!(exists(\"testing\"))) {\n        testFile <- \"test.csv\"\n        testFilePath <- paste(getwd(),\"data\", testFile, sep = \"/\")\n        testing <- read.csv(testFilePath, na.strings = c(\"NA\",\"#DIV/0!\",\"\"))\n}\n```\n\n###Training-Set cleaning and pre-processing\n\nNames’s Coherence Check\n```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results=\"hide\"}\nall.equal(colnames(test)[1:length(colnames(test))-1], colnames(train)[1:length(colnames(train))-1])\n```\n\nTo ease the computation and due to the low informativity loss, the dataset is cleaned from the variables with an high share of NAs and from the ones characterized by low variance.\n\n```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results=\"hide\"}\nnearzero <- nearZeroVar(train, saveMetrics = TRUE)\ntrain <- train[, !nearzero$nzv]\n```\n\nVariables with more than 50% missing values are removed\n\n```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results=\"hide\"}\ntoberem <- sapply(colnames(train), function(x) if(sum(is.na(train[, x])) > 0.50*nrow(train))    {return(TRUE)\n}else{\nreturn(FALSE)\n}\n)\ntrain <- train[, !toberem]\n```\n\nVariables related with data acquisition (like: id, timestamps, individuals’ names, etc.) are not suitable to be used in prediction and are removed\n```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results=\"hide\"}\ntrain <- train[, -(1:6)]\n```\n\nCorrelation analysis:\n```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results=\"hide\"}\nHcorr <- caret::findCorrelation(cor(train[, -53]), cutoff=0.8)\nnames(train)[Hcorr]\n```\n\nMany variables are highly correlated. PCA will be used in the pre-processing. After the data cleaning the variables selected to specify the model are:\n```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results=\"hide\"}\nnames(train)\n```\n\n\n\n###Partioning the training set into two\nPartioning Training data set into two data sets, 60% for myTraining, 40% for myTesting:\n\n```{r, echo=F, message=FALSE, warning=FALSE, cache = TRUE, results=\"hide\"}\ninTrain <- createDataPartition(y=training$classe, p=0.6, list=FALSE)\nmyTraining <- training[inTrain, ]; myTesting <- training[-inTrain, ]\ndim(myTraining); dim(myTesting)\n\n```\n\n```{r, echo=T, message=FALSE, warning=FALSE, results=\"as-is\"}\nhead(testing)\nhead(training)\n\n```\n",
    "created" : 1449971375324.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "103921196",
    "id" : "EB6D52A9",
    "lastKnownWriteTime" : 1450071381,
    "path" : "~/GitHub/machinelearning1/PredictiveBarbellLifts.Rmd",
    "project_path" : "PredictiveBarbellLifts.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_markdown"
}